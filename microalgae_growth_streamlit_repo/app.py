from __future__ import annotations

import os
import streamlit as st
import pandas as pd

from src.db import (
    get_engine, init_db, list_tables, table_count, read_table,
    upsert_study_df, upsert_organism_df,
    insert_experiments, insert_outcomes, insert_timeseries,
    read_training_join
)
from src.io_utils import read_excel_sheets, read_csv_files
from src.template import build_empty_template, TEMPLATE_COLUMNS
from src.validators import validate_df
from src.model import ModelParams, simulate

st.set_page_config(page_title="Microalgae Growth DB + Predictor", layout="wide")

# Secrets -> env
try:
    if "DATABASE_URL" in st.secrets and not os.environ.get("DATABASE_URL"):
        os.environ["DATABASE_URL"] = str(st.secrets["DATABASE_URL"])
except Exception:
    pass

engine = get_engine()

st.title("ğŸ§« Microalgae Growth Database / å¾®è—»ç”Ÿé•¿æ•°æ®åº“")
st.markdown(
    """
**GitHub:** `https://github.com/<YOUR-ACCOUNT>/microalgae-growth-db`  
> Replace the URL above with your repo link after you push to GitHub.
"""
)

# Sidebar (no indentation pitfalls)
st.sidebar.header("Database / æ•°æ®åº“")
if os.environ.get("DATABASE_URL", "").strip():
    st.sidebar.success("Backend: Postgres / è¿œç¨‹æ•°æ®åº“")
else:
    st.sidebar.info("Backend: SQLite (local) / æœ¬åœ°æ•°æ®åº“: data/microalgae.db")

if st.sidebar.button("Initialize / Create Tables\nåˆå§‹åŒ–/å»ºè¡¨", type="primary"):
    init_db(engine)
    st.toast("Database initialized / å·²å»ºè¡¨", icon="âœ…")

st.sidebar.divider()
st.sidebar.caption("Tip: For Streamlit Cloud persistence, use Postgres via `DATABASE_URL` in Secrets.")

tab_upload, tab_browse, tab_predict, tab_quality, tab_help = st.tabs([
    "Upload / Update ä¸Šä¼ æ›´æ–°",
    "Browse æµè§ˆ",
    "Predict / æ¨¡å‹é¢„æµ‹",
    "Quality è´¨æ§",
    "Help å¸®åŠ©",
])

with tab_upload:
    st.subheader("Upload your data (Excel or CSV) / ä¸Šä¼ æ•°æ®ï¼ˆExcel æˆ– CSVï¼‰")
    st.markdown(
        """
**æ¨èï¼š** ä¸Šä¼ ä¸€ä¸ª Excelï¼ˆå¤š sheetï¼šstudy / organism / media / reactor / experiment / outcome / timeseriesï¼‰  
æˆ–ä¸Šä¼ å¤šä¸ª CSV æ–‡ä»¶ï¼Œæ–‡ä»¶åå¿…é¡»ä¸ºï¼š`study.csv`, `organism.csv`, `media.csv`, `reactor.csv`, `experiment.csv`, `outcome.csv`, `timeseries.csv`
"""
    )

    template_bytes = build_empty_template()
    st.download_button(
        "â¬‡ï¸ Download Excel Template / ä¸‹è½½æ¨¡æ¿",
        data=template_bytes,
        file_name="microalgae_db_template.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True
    )

    st.divider()

    mode = st.radio(
        "Import mode / å¯¼å…¥æ¨¡å¼",
        options=[
            "Append (add new rows) / è¿½åŠ ",
            "Upsert dimensions (study/organism) + append facts / ç»´è¡¨æ›´æ–°+äº‹å®è¡¨è¿½åŠ ",
        ],
        index=1
    )

    uploaded_excel = st.file_uploader(
        "Upload Excel (multi-sheet) / ä¸Šä¼  Excelï¼ˆå¤š Sheetï¼‰",
        type=["xlsx"],
        accept_multiple_files=False
    )
    uploaded_csvs = st.file_uploader(
        "Or upload multiple CSV files / æˆ–ä¸Šä¼ å¤šä¸ª CSV æ–‡ä»¶",
        type=["csv"],
        accept_multiple_files=True
    )

    if st.button("ğŸš€ Import / å¯¼å…¥", type="primary", use_container_width=True):
        init_db(engine)

        if uploaded_excel is None and not uploaded_csvs:
            st.warning("Please upload an Excel or CSV files first. / è¯·å…ˆä¸Šä¼  Excel æˆ– CSVã€‚")
            st.stop()

        if uploaded_excel is not None:
            sheets = read_excel_sheets(uploaded_excel.getvalue())
            source_label = f"excel:{uploaded_excel.name}"
        else:
            files = [(f.name, f.getvalue()) for f in uploaded_csvs]
            sheets = read_csv_files(files)
            source_label = "csv:multiple"

        known = set(TEMPLATE_COLUMNS.keys())
        recognized = {k: v for k, v in sheets.items() if k in known}
        ignored = [k for k in sheets.keys() if k not in known]
        if ignored:
            st.info(f"Ignored sheets/files: {ignored}")

        all_errors, all_warnings = [], []
        for t, df in recognized.items():
            errs, warns = validate_df(t, df)
            all_errors += [f"[{t}] {e}" for e in errs]
            all_warnings += [f"[{t}] {w}" for w in warns]

        if all_errors:
            st.error("Validation failed / æ ¡éªŒå¤±è´¥")
            st.write("\n".join(all_errors))
            st.stop()

        if all_warnings:
            st.warning("Warnings / è­¦å‘Šï¼ˆä¸é˜»æ­¢å¯¼å…¥ï¼‰")
            for w in all_warnings:
                st.write("- " + w)

        msgs = []

        if "study" in recognized and len(recognized["study"]) > 0:
            if "Upsert" in mode:
                ins, upd = upsert_study_df(engine, recognized["study"])
                msgs.append(f"study: inserted {ins}, updated {upd}")
            else:
                recognized["study"].to_sql("study", engine, if_exists="append", index=False)
                msgs.append(f"study: appended {len(recognized['study'])}")

        if "organism" in recognized and len(recognized["organism"]) > 0:
            if "Upsert" in mode:
                ins, upd = upsert_organism_df(engine, recognized["organism"])
                msgs.append(f"organism: inserted {ins}, updated {upd}")
            else:
                recognized["organism"].to_sql("organism", engine, if_exists="append", index=False)
                msgs.append(f"organism: appended {len(recognized['organism'])}")

        if "media" in recognized and len(recognized["media"]) > 0:
            recognized["media"].to_sql("media", engine, if_exists="append", index=False)
            msgs.append(f"media: appended {len(recognized['media'])}")

        if "reactor" in recognized and len(recognized["reactor"]) > 0:
            recognized["reactor"].to_sql("reactor", engine, if_exists="append", index=False)
            msgs.append(f"reactor: appended {len(recognized['reactor'])}")

        if "experiment" in recognized and len(recognized["experiment"]) > 0:
            ins, upd = insert_experiments(engine, recognized["experiment"], source_label=source_label)
            msgs.append(f"experiment: inserted {ins}, updated {upd}")

        if "outcome" in recognized and len(recognized["outcome"]) > 0:
            ins = insert_outcomes(engine, recognized["outcome"], source_label=source_label)
            msgs.append(f"outcome: inserted {ins}")

        if "timeseries" in recognized and len(recognized["timeseries"]) > 0:
            ins = insert_timeseries(engine, recognized["timeseries"], source_label=source_label)
            msgs.append(f"timeseries: inserted {ins}")

        st.success("Import completed / å¯¼å…¥å®Œæˆ âœ…")
        for m in msgs:
            st.write("- " + m)

with tab_browse:
    st.subheader("Browse tables / æµè§ˆæ•°æ®åº“è¡¨")
    init_db(engine)

    try:
        tables = list_tables(engine)
    except Exception:
        tables = []

    if not tables:
        st.info("No tables found. Click 'Initialize' first. / å…ˆç‚¹åˆå§‹åŒ–ã€‚")
    else:
        table = st.selectbox("Select table / é€‰æ‹©è¡¨", options=tables, index=0)
        n = table_count(engine, table)
        st.caption(f"Rows / è¡Œæ•°: {n}")
        df = read_table(engine, table, limit=2000)
        st.dataframe(df, use_container_width=True, height=520)
        st.download_button(
            "â¬‡ï¸ Download preview CSV / ä¸‹è½½é¢„è§ˆCSV",
            data=df.to_csv(index=False).encode("utf-8"),
            file_name=f"{table}_preview.csv",
            mime="text/csv",
            use_container_width=True
        )

with tab_predict:
    st.subheader("Predict growth & composition / é¢„æµ‹ç”Ÿé•¿ä¸ç»„æˆï¼ˆMVPï¼‰")
    st.caption("Flux charts are proxy indices (heuristic), not real GEM/FBA flux. / é€šé‡å›¾ä¸ºä»£ç†æŒ‡æ ‡ï¼ˆæ¼”ç¤ºï¼‰ï¼ŒéçœŸå® FBAã€‚")

    c1, c2 = st.columns([1, 1])
    with c1:
        trophic_mode = st.selectbox("Trophic mode / è¥å…»æ¨¡å¼", ["mixotrophic", "heterotrophic", "autotrophic"], index=0)
        carbon_source = st.selectbox("Carbon source / ç¢³æºï¼ˆç±»å‹ï¼‰", ["glucose", "acetate", "glycerol", "none (CO2 only)"], index=0)
        C0 = st.number_input("Initial carbon (g/L) / åˆå§‹ç¢³æºæµ“åº¦ (g/L)", min_value=0.0, value=10.0, step=0.5)
        nitrogen_source = st.selectbox("Nitrogen source / æ°®æºï¼ˆç±»å‹ï¼‰", ["nitrate", "ammonium", "urea"], index=0)
        N0 = st.number_input("Initial nitrogen as N (mmol/L) / åˆå§‹æ°®ï¼ˆä»¥ N è®¡, mmol/Lï¼‰", min_value=0.0, value=5.0, step=0.5)
        X0 = st.number_input("Initial biomass (g/L) / åˆå§‹ç”Ÿç‰©é‡ (g/L)", min_value=0.0, value=0.1, step=0.05)
    with c2:
        pH = st.number_input("pH", min_value=0.0, max_value=14.0, value=7.0, step=0.1)
        I = st.number_input("Light intensity (Î¼mol mâ»Â² sâ»Â¹) / å…‰ç…§å¼ºåº¦", min_value=0.0, value=150.0, step=10.0)
        T = st.number_input("Temperature (Â°C) / æ¸©åº¦", min_value=-10.0, max_value=60.0, value=25.0, step=1.0)
        DO = st.number_input("Dissolved O2 (mg/L) / æº¶è§£æ°§", min_value=0.0, value=8.0, step=0.5)
        CO2 = st.number_input("Gas CO2 (%) / æ°”ç›¸ CO2(%)", min_value=0.0, max_value=100.0, value=2.0, step=0.2)
        rpm = st.number_input("Mixing (rpm) / æ…æ‹Œè½¬é€Ÿ", min_value=0.0, value=300.0, step=10.0)

    st.divider()
    duration = st.number_input("Duration (days) / æ¨¡æ‹Ÿå¤©æ•°", min_value=0.5, value=7.0, step=0.5)
    use_db_guess = st.checkbox("Guess parameters from your DB / ä»æ•°æ®åº“ä¼°è®¡å‚æ•°ï¼ˆå¿«é€Ÿï¼‰", value=True)

    params = ModelParams()
    if use_db_guess:
        try:
            init_db(engine)
            train = read_training_join(engine)
            if len(train) > 5:
                mu_obs = pd.to_numeric(train.get("mu_d1"), errors="coerce").dropna()
                x_obs = pd.to_numeric(train.get("biomass_gL"), errors="coerce").dropna()
                p_obs = pd.to_numeric(train.get("protein_pct_dw"), errors="coerce").dropna()
                l_obs = pd.to_numeric(train.get("lipid_pct_dw"), errors="coerce").dropna()
                if len(mu_obs) > 0:
                    params.mu_max_d1 = float(mu_obs.quantile(0.9))
                if len(x_obs) > 0:
                    params.X_max_gL = float(max(5.0, x_obs.max() * 1.3))
                if len(p_obs) > 0:
                    params.protein_max = float(min(0.8, p_obs.max() / 100.0))
                if len(l_obs) > 0:
                    params.lipid_max = float(min(0.8, l_obs.max() / 100.0))
        except Exception:
            pass

    with st.expander("Model parameters / æ¨¡å‹å‚æ•°ï¼ˆå¯é€‰ï¼‰", expanded=False):
        st.write("Keep defaults unless you want to tune. / é»˜è®¤å³å¯ã€‚")
        col1, col2, col3 = st.columns(3)
        with col1:
            params.mu_max_d1 = st.number_input("mu_max (1/day)", min_value=0.0, value=float(params.mu_max_d1), step=0.1)
            params.X_max_gL = st.number_input("X_max (g/L)", min_value=0.1, value=float(params.X_max_gL), step=1.0)
        with col2:
            params.K_I = st.number_input("K_I (Î¼mol mâ»Â² sâ»Â¹)", min_value=0.0, value=float(params.K_I), step=10.0)
            params.K_C = st.number_input("K_C (g/L)", min_value=0.0, value=float(params.K_C), step=0.2)
            params.K_N = st.number_input("K_N (mmol/L)", min_value=0.0, value=float(params.K_N), step=0.2)
        with col3:
            params.pH_opt = st.number_input("pH_opt", min_value=0.0, max_value=14.0, value=float(params.pH_opt), step=0.1)
            params.pH_sigma = st.number_input("pH_sigma", min_value=0.1, value=float(params.pH_sigma), step=0.1)
            params.Q10 = st.number_input("Q10", min_value=0.5, value=float(params.Q10), step=0.1)

    if st.button("ğŸ§ª Simulate / æ¨¡æ‹Ÿé¢„æµ‹", type="primary", use_container_width=True):
        C0_use = 0.0 if carbon_source.startswith("none") else float(C0)
        df_sim = simulate(
            trophic_mode=trophic_mode,
            carbon_source=carbon_source,
            C0_gL=C0_use,
            nitrogen_source=nitrogen_source,
            N0_mM=float(N0),
            X0_gL=float(X0),
            pH=float(pH),
            light_uE_m2_s=float(I),
            temperature_C=float(T),
            dissolved_oxygen_mgL=float(DO),
            gas_co2_percent=float(CO2),
            mixing_rpm=float(rpm),
            duration_d=float(duration),
            dt_d=0.02,
            params=params
        )

        st.success("Simulation done / æ¨¡æ‹Ÿå®Œæˆ âœ…")

        st.write("### Biomass & content / ç”Ÿç‰©é‡ä¸ç»„æˆ")
        cA, cB = st.columns(2)
        with cA:
            st.line_chart(df_sim.set_index("time_d")[["biomass_gL"]])
        with cB:
            st.line_chart(df_sim.set_index("time_d")[["protein_pct_dw", "lipid_pct_dw", "carb_pct_dw"]])

        st.write("### Metabolic flux (proxy) / ä»£è°¢é€šé‡ï¼ˆä»£ç†æŒ‡æ ‡ï¼‰")
        st.line_chart(df_sim.set_index("time_d")[["flux_glycolysis", "flux_ppp", "flux_tca"]])

        st.download_button(
            "â¬‡ï¸ Download simulation CSV / ä¸‹è½½æ¨¡æ‹Ÿç»“æœ CSV",
            data=df_sim.to_csv(index=False).encode("utf-8"),
            file_name="simulation_results.csv",
            mime="text/csv",
            use_container_width=True
        )
        st.dataframe(df_sim.head(200), use_container_width=True, height=320)

with tab_quality:
    st.subheader("Quick quality checks / å¿«é€Ÿè´¨æ§")
    init_db(engine)
    try:
        tables = list_tables(engine)
    except Exception:
        tables = []
    if not tables:
        st.info("Initialize DB first. / è¯·å…ˆåˆå§‹åŒ–æ•°æ®åº“ã€‚")
    else:
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("study rows", table_count(engine, "study") if "study" in tables else 0)
        with c2:
            st.metric("experiment rows", table_count(engine, "experiment") if "experiment" in tables else 0)
        with c3:
            st.metric("outcome rows", table_count(engine, "outcome") if "outcome" in tables else 0)

with tab_help:
    st.subheader("How to use / ä½¿ç”¨è¯´æ˜")
    st.markdown(
        """
### ä¸­æ–‡
- è¿™ä¸ª App = **æ•°æ®åº“ + é¢„æµ‹æ¨¡å‹ï¼ˆMVPï¼‰**
- Predictï¼šè¾“å…¥åŸ¹å…»æ¡ä»¶ â†’ è¾“å‡ºç”Ÿç‰©é‡/è›‹ç™½/æ²¹è„‚æ›²çº¿ + 3 æ¡ä»£ç†é€šé‡æ›²çº¿  
- è‹¥ä½ è¦çœŸæ­£çš„ FBA/dFBA ä»£è°¢é€šé‡å›¾ + â€œç‚¹ ALA è‡ªåŠ¨å‡ºè¡¥æ–™æ–¹æ¡ˆâ€ï¼Œä¸‹ä¸€æ­¥éœ€è¦æ¥ COBRApy + ç‰©ç§ GEMã€‚

### English
- This app = **database + predictor (MVP)**
- Predict: input conditions â†’ biomass/protein/lipid curves + 3 proxy flux curves  
- For real FBA/dFBA flux maps + â€œclick ALA â†’ feeding planâ€, next step needs COBRApy + a species GEM.
"""
    )
